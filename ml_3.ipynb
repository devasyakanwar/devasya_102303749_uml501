{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w9rbJjmJDTBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4e5f71-cfba-4319-f1c4-0eefdd5e66bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score: 0.9179971706985147\n",
            "R2 Score: 0.9145677884802818\n",
            "R2 Score: 0.9116116385364478\n",
            "R2 Score: 0.9193091764960816\n",
            "R2 Score: 0.9243869413350316\n",
            "\n",
            "Best Beta: [1.23161736e+06 2.30225051e+05 1.63956839e+05 1.21115120e+05\n",
            " 7.83467170e+02 1.50662447e+05]\n",
            "Final R2 Score on 30% test data with best beta: 0.9147458156636434\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def least_square_beta(X, y):\n",
        "    X = np.insert(X, 0, 1, axis=1)\n",
        "    beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "    return beta\n",
        "\n",
        "df = pd.read_csv('/content/USA_Housing.csv')\n",
        "\n",
        "X = df.drop('Price', axis=1).values\n",
        "y = df['Price'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "r2_scores = []\n",
        "betas = []\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    beta = least_square_beta(X_train, y_train)\n",
        "    betas.append(beta)\n",
        "    y_pred = np.insert(X_test, 0, 1, axis=1) @ beta\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "    print(f\"R2 Score: {r2}\")\n",
        "\n",
        "best_beta = betas[np.argmax(r2_scores)]\n",
        "print(f\"\\nBest Beta: {best_beta}\")\n",
        "\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "y_pred_final = np.insert(X_test_final, 0, 1, axis=1) @ best_beta\n",
        "final_r2 = r2_score(y_test_final, y_pred_final)\n",
        "print(f\"Final R2 Score on 30% test data with best beta: {final_r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "def gradient_descent(X, y, learning_rate, iterations):\n",
        "    m, n = X.shape\n",
        "    X_b = np.insert(X, 0, 1, axis=1)  # Add intercept term\n",
        "    beta = np.zeros(n + 1)\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        gradients = (2/m) * X_b.T @ (X_b @ beta - y)\n",
        "        beta -= learning_rate * gradients\n",
        "\n",
        "    return beta\n",
        "\n",
        "df = pd.read_csv('/content/USA_Housing.csv')\n",
        "\n",
        "\n",
        "X = df.drop('Price', axis=1).values\n",
        "y = df['Price'].values\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.44, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.68, random_state=42)\n",
        "\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"\\nTraining with learning rate: {lr}\")\n",
        "    beta = gradient_descent(X_train, y_train, lr, 1000)\n",
        "\n",
        "    X_val_b = np.insert(X_val, 0, 1, axis=1)\n",
        "    y_pred_val = X_val_b @ beta\n",
        "    r2_val = r2_score(y_val, y_pred_val)\n",
        "\n",
        "    X_test_b = np.insert(X_test, 0, 1, axis=1)\n",
        "    y_pred_test = X_test_b @ beta\n",
        "    r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "    results.append({'learning_rate': lr, 'beta': beta, 'R2_val': r2_val, 'R2_test': r2_test})\n",
        "    print(f\"R2 Score on Validation Set: {r2_val}\")\n",
        "    print(f\"R2 Score on Test Set: {r2_test}\")\n",
        "\n",
        "best_result = max(results, key=lambda x: x['R2_val'])\n",
        "print(\"\\nBest Regression Coefficients based on Validation Set R2 Score:\")\n",
        "print(f\"Learning Rate: {best_result['learning_rate']}\")\n",
        "print(f\"Coefficients (Beta): {best_result['beta']}\")\n",
        "print(f\"R2 Score on Validation Set: {best_result['R2_val']}\")\n",
        "print(f\"R2 Score on Test Set: {best_result['R2_test']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBVNfaWQa9tj",
        "outputId": "27850e76-23b6-4ba4-ce3b-7ca2585ad1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with learning rate: 0.001\n",
            "R2 Score on Validation Set: 0.6467117844424869\n",
            "R2 Score on Test Set: 0.6531360260800088\n",
            "\n",
            "Training with learning rate: 0.01\n",
            "R2 Score on Validation Set: 0.9202206893493433\n",
            "R2 Score on Test Set: 0.9133419052066929\n",
            "\n",
            "Training with learning rate: 0.1\n",
            "R2 Score on Validation Set: 0.9202207766800662\n",
            "R2 Score on Test Set: 0.9133419747998835\n",
            "\n",
            "Training with learning rate: 1\n",
            "R2 Score on Validation Set: -inf\n",
            "R2 Score on Test Set: -inf\n",
            "\n",
            "Best Regression Coefficients based on Validation Set R2 Score:\n",
            "Learning Rate: 0.1\n",
            "Coefficients (Beta): [1232180.27200919  230645.88389435  165328.94019375  120045.00851908\n",
            "    2945.02108903  151375.22971285]\n",
            "R2 Score on Validation Set: 0.9202207766800662\n",
            "R2 Score on Test Set: 0.9133419747998835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "column_names = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
        "                \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\",\n",
        "                \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
        "                \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\",\n",
        "                \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
        "                \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data',\n",
        "                 names=column_names, na_values='?')\n",
        "\n",
        "for col in ['normalized_losses', 'horsepower', 'peak_rpm', 'price', 'bore', 'stroke']:\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    df[col] = imputer.fit_transform(df[[col]])\n",
        "\n",
        "df.dropna(subset=['price'], inplace=True)\n",
        "\n",
        "door_map = {'two': 2, 'four': 4}\n",
        "df['num_doors'] = df['num_doors'].map(door_map).fillna(4)\n",
        "\n",
        "cylinder_map = {'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'eight': 8, 'twelve': 12}\n",
        "df['num_cylinders'] = df['num_cylinders'].map(cylinder_map)\n",
        "\n",
        "df = pd.get_dummies(df, columns=['body_style', 'drive_wheels'], drop_first=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for col in ['make', 'aspiration', 'engine_location', 'fuel_type']:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "df['fuel_system'] = df['fuel_system'].apply(lambda x: 1 if 'pfi' in str(x) else 0)\n",
        "df['engine_type'] = df['engine_type'].apply(lambda x: 1 if 'ohc' in str(x) else 0)\n",
        "\n",
        "X = df.drop('price', axis=1)\n",
        "y = df['price']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(X_train, y_train)\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "r2_before_pca = r2_score(y_test, y_pred)\n",
        "print(f\"R2 Score before PCA: {r2_before_pca}\")\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
        "\n",
        "linear_reg_pca = LinearRegression()\n",
        "linear_reg_pca.fit(X_train_pca, y_train_pca)\n",
        "y_pred_pca = linear_reg_pca.predict(X_test_pca)\n",
        "r2_after_pca = r2_score(y_test_pca, y_pred_pca)\n",
        "print(f\"R2 Score after PCA: {r2_after_pca}\")\n",
        "\n",
        "if r2_after_pca > r2_before_pca:\n",
        "    print(\"\\nPerformance improved after PCA.\")\n",
        "elif r2_after_pca < r2_before_pca:\n",
        "    print(\"\\nPerformance decreased after PCA.\")\n",
        "else:\n",
        "    print(\"\\nPerformance remained the same after PCA.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmDko_JQu7MP",
        "outputId": "7f2289fb-3751-4495-f73e-2a6d40a6dadb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score before PCA: 0.804442243576259\n",
            "R2 Score after PCA: 0.7500675882701553\n",
            "\n",
            "Performance decreased after PCA.\n"
          ]
        }
      ]
    }
  ]
}